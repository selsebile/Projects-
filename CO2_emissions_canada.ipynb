{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# ***Introduction:***\n",
        "\n",
        "Le changement climatique est l'un des défis majeurs de notre époque, et la réduction des émissions de CO2 est cruciale pour atténuer ses effets. Dans ce projet, nous avons entrepris une analyse des émissions de CO2 des véhicules au Canada en utilisant des techniques de machine learning, plus spécifiquement le clustering. Notre objectif était de segmenter les véhicules en différents clusters basés sur leurs caractéristiques et leurs émissions de CO2. Pour réaliser cette tâche, nous avons utilisé Apache Spark, un framework de traitement de données massivement parallèle qui nous permet de gérer et de traiter efficacement de grandes quantités de données."
      ],
      "metadata": {
        "id": "8KTo4rQSytoO"
      },
      "id": "8KTo4rQSytoO"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Binome : **\n",
        "\n",
        "\n",
        "*   Dounia KAMEL\n",
        "*   Selsabile KACHA\n",
        "\n"
      ],
      "metadata": {
        "id": "MKybvqNtzERf"
      },
      "id": "MKybvqNtzERf"
    },
    {
      "cell_type": "markdown",
      "id": "8292ff61",
      "metadata": {
        "id": "8292ff61"
      },
      "source": [
        "## Initialisation de la Session Spark\n",
        "Ce bloc de code importe la bibliothèque nécessaire et initialise une session Spark en mode local avec toutes les ressources disponibles, et nomme l'application \"Intro\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "processed-stick",
      "metadata": {
        "id": "processed-stick"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .master('local[*]') \\\n",
        "    .appName(\"Intro\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c50cd4d7",
      "metadata": {
        "id": "c50cd4d7"
      },
      "source": [
        "## Définition du Schéma de Données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "special-portable",
      "metadata": {
        "id": "special-portable"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructField, StructType, StringType, DoubleType\n",
        "\n",
        "custom_schema = StructType([\n",
        "    StructField(\"Make\", StringType(), True),\n",
        "    StructField(\"Model\", StringType(), True),\n",
        "    StructField(\"Vehicle Class\", StringType(), True),\n",
        "    StructField(\"Cylinders\", DoubleType(), True),\n",
        "    StructField(\"Transmission\", StringType(), True),\n",
        "    StructField(\"Fuel Type\", StringType(), True),\n",
        "    StructField(\"Fuel Consumption City (L/100 km)\", DoubleType(), True),\n",
        "    StructField(\"Fuel Consumption Hwy (L/100 km)\", DoubleType(), True),\n",
        "    StructField(\"Fuel Consumption Comb (L/100 km)\", DoubleType(), True),\n",
        "    StructField(\"Fuel Consumption Comb (mpg)\", DoubleType(), True),\n",
        "    StructField(\"CO2\", DoubleType(), True)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efb2ff90",
      "metadata": {
        "id": "efb2ff90"
      },
      "source": [
        "\n",
        "## Chargement des Données avec un Schéma Personnalisé"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "green-berlin",
      "metadata": {
        "id": "green-berlin"
      },
      "outputs": [],
      "source": [
        "co2_data = spark.read.format(\"csv\")\\\n",
        "    .schema(custom_schema) \\\n",
        "    .option(\"header\", True) \\\n",
        "    .load(\"CO2_Emissions_Canada.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "raised-equality",
      "metadata": {
        "id": "raised-equality",
        "outputId": "f948fc2e-6e01-4f47-fbd9-be42828908c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
              " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=None, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "co2_data.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "intermediate-israeli",
      "metadata": {
        "id": "intermediate-israeli"
      },
      "outputs": [],
      "source": [
        "cols_only_continues_values = {'Fuel Consumption City (L/100 km)':0}\n",
        "#                               \"Fuel Consumption Hwy (L/100 km)\",\n",
        "#         \"Fuel Consumption Comb (L/100 km)\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cultural-correspondence",
      "metadata": {
        "id": "cultural-correspondence"
      },
      "outputs": [],
      "source": [
        "co2_data = co2_data.fillna(0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mature-checkout",
      "metadata": {
        "id": "mature-checkout",
        "outputId": "4ae81605-450c-40ef-c80f-4d72f232a229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Make: string (nullable = true)\n",
            " |-- Model: string (nullable = true)\n",
            " |-- Vehicle Class: string (nullable = true)\n",
            " |-- Cylinders: double (nullable = false)\n",
            " |-- Transmission: string (nullable = true)\n",
            " |-- Fuel Type: string (nullable = true)\n",
            " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
            " |-- CO2: double (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "co2_data.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "level-mixture",
      "metadata": {
        "id": "level-mixture",
        "outputId": "18979dc2-b62c-45b4-d9d3-8de983be1dc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.0, Transmission='4', Fuel Type='AS5', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=9.9, Fuel Consumption Comb (L/100 km)=6.7, Fuel Consumption Comb (mpg)=8.5, CO2=33.0),\n",
              " Row(Make='ACURA', Model='ILX', Vehicle Class='COMPACT', Cylinders=2.4, Transmission='4', Fuel Type='M6', Fuel Consumption City (L/100 km)=0.0, Fuel Consumption Hwy (L/100 km)=11.2, Fuel Consumption Comb (L/100 km)=7.7, Fuel Consumption Comb (mpg)=9.6, CO2=29.0)]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "co2_data.take(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "usual-sellers",
      "metadata": {
        "id": "usual-sellers"
      },
      "source": [
        "## Preparation des données pour la régression"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "egyptian-embassy",
      "metadata": {
        "id": "egyptian-embassy"
      },
      "source": [
        "transformer les feature colonnes en colonnes indexés :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "expanded-seating",
      "metadata": {
        "id": "expanded-seating"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import FeatureHasher\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "cols = [\"Make\", \"Model\", \"Vehicle Class\",\"Cylinders\",\"Transmission\",\"Fuel Type\",\n",
        "        \"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
        "        \"Fuel Consumption Comb (L/100 km)\",\"Fuel Consumption Comb (mpg)\"]\n",
        "\n",
        "cols_only_continues = [\"Fuel Consumption City (L/100 km)\", \"Fuel Consumption Hwy (L/100 km)\",\n",
        "        \"Fuel Consumption Comb (L/100 km)\"]\n",
        "\n",
        "hasher = FeatureHasher(outputCol=\"hashed_features\", inputCols=cols_only_continues)\n",
        "data = hasher.transform(co2_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hairy-mountain",
      "metadata": {
        "id": "hairy-mountain",
        "outputId": "f788003a-a0d7-4eab-cd1f-1f2c55977cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------+\n",
            "|hashed_features                              |\n",
            "+---------------------------------------------+\n",
            "|(262144,[38607,109231,228390],[0.0,9.9,6.7]) |\n",
            "|(262144,[38607,109231,228390],[0.0,11.2,7.7])|\n",
            "|(262144,[38607,109231,228390],[0.0,6.0,5.8]) |\n",
            "|(262144,[38607,109231,228390],[0.0,12.7,9.1])|\n",
            "|(262144,[38607,109231,228390],[0.0,12.1,8.7])|\n",
            "+---------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.select(\"hashed_features\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "closed-boulder",
      "metadata": {
        "id": "closed-boulder",
        "outputId": "81f619aa-06ed-4907-92fd-ceeeecf15962"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(hashed_features=SparseVector(262144, {38607: 0.0, 109231: 9.9, 228390: 6.7}))]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.select(\"hashed_features\").take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vulnerable-right",
      "metadata": {
        "id": "vulnerable-right",
        "outputId": "8a4d4630-1992-4bac-e260-9b068d40ad69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------+\n",
            "|hashed_features                              |\n",
            "+---------------------------------------------+\n",
            "|(262144,[38607,109231,228390],[0.0,9.9,6.7]) |\n",
            "|(262144,[38607,109231,228390],[0.0,11.2,7.7])|\n",
            "|(262144,[38607,109231,228390],[0.0,6.0,5.8]) |\n",
            "|(262144,[38607,109231,228390],[0.0,12.7,9.1])|\n",
            "|(262144,[38607,109231,228390],[0.0,12.1,8.7])|\n",
            "+---------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.select(\"hashed_features\").show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stupid-modeling",
      "metadata": {
        "id": "stupid-modeling",
        "outputId": "d7a76f20-a525-4961-8809-fe091af01acc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Make: string (nullable = true)\n",
            " |-- Model: string (nullable = true)\n",
            " |-- Vehicle Class: string (nullable = true)\n",
            " |-- Cylinders: double (nullable = false)\n",
            " |-- Transmission: string (nullable = true)\n",
            " |-- Fuel Type: string (nullable = true)\n",
            " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
            " |-- CO2: double (nullable = false)\n",
            " |-- hashed_features: vector (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "valuable-roots",
      "metadata": {
        "id": "valuable-roots"
      },
      "source": [
        "# Séléctionner les features les plus importantes:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6a212e",
      "metadata": {
        "id": "9b6a212e"
      },
      "source": [
        "Ce bloc de code utilise le sélecteur de caractéristiques univariées (UnivariateFeatureSelector) pour sélectionner les caractéristiques les plus pertinentes à partir de hashed_features en fonction de leur relation avec l'étiquette CO2. Les caractéristiques sélectionnées sont stockées dans une nouvelle colonne nommée selectedFeatures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "breeding-christmas",
      "metadata": {
        "id": "breeding-christmas"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import UnivariateFeatureSelector\n",
        "\n",
        "selector = UnivariateFeatureSelector(outputCol=\"selectedFeatures\", featuresCol=\"hashed_features\", labelCol=\"CO2\")\n",
        "\n",
        "selector.setFeatureType(\"continuous\")\n",
        "selector.setLabelType(\"continuous\")\n",
        "\n",
        "model = selector.fit(data)\n",
        "data = model.transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "affiliated-moscow",
      "metadata": {
        "id": "affiliated-moscow"
      },
      "source": [
        " ## Modélisation de Latent Dirichlet Allocation (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "actual-newfoundland",
      "metadata": {
        "id": "actual-newfoundland",
        "outputId": "bbddd3bf-3f0b-4d90-b94b-0a667a14072c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors, SparseVector\n",
        "from pyspark.ml.clustering import LDA\n",
        "\n",
        "\n",
        "lda = LDA(k=2, seed=1, optimizer=\"em\",featuresCol=\"selectedFeatures\")\n",
        "lda.setMaxIter(100)\n",
        "\n",
        "\n",
        "lda.clear(lda.maxIter)\n",
        "lda_model = lda.fit(data)\n",
        "lda_model.setSeed(1)\n",
        "\n",
        "# check if the model itself is distributed across Spark executres\n",
        "lda_model.isDistributed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pretty-appearance",
      "metadata": {
        "id": "pretty-appearance",
        "outputId": "5c636b04-0fd1-46c3-f675-226bfcceca78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+-----------+--------------------+\n",
            "|topic|termIndices|         termWeights|\n",
            "+-----+-----------+--------------------+\n",
            "|    0|   [48, 49]|[0.58104675033297...|\n",
            "|    1|   [48, 49]|[0.58168999987474...|\n",
            "+-----+-----------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lda_model.describeTopics().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "configured-triple",
      "metadata": {
        "id": "configured-triple",
        "outputId": "a4bfbb5a-a4c4-4813-9cbd-d55395b361cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lda_model.vocabSize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "embedded-optics",
      "metadata": {
        "id": "embedded-optics"
      },
      "outputs": [],
      "source": [
        "lda_predictions = lda_model.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "respected-southwest",
      "metadata": {
        "id": "respected-southwest",
        "outputId": "e0bf6601-64c3-40a0-a371-a1bb0d97ee7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Make: string (nullable = true)\n",
            " |-- Model: string (nullable = true)\n",
            " |-- Vehicle Class: string (nullable = true)\n",
            " |-- Cylinders: double (nullable = false)\n",
            " |-- Transmission: string (nullable = true)\n",
            " |-- Fuel Type: string (nullable = true)\n",
            " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
            " |-- CO2: double (nullable = false)\n",
            " |-- hashed_features: vector (nullable = true)\n",
            " |-- selectedFeatures: vector (nullable = true)\n",
            " |-- topicDistribution: vector (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lda_predictions.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exotic-endorsement",
      "metadata": {
        "id": "exotic-endorsement",
        "outputId": "7fa21bd8-cb5a-4b2e-8bd3-6575e11cda7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------------------------------------+\n",
            "|topicDistribution                       |\n",
            "+----------------------------------------+\n",
            "|[0.4999956369386229,0.5000043630613772] |\n",
            "|[0.49999497253338004,0.5000050274666199]|\n",
            "+----------------------------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lda_predictions.select(\"topicDistribution\").show(2,truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "refined-brake",
      "metadata": {
        "id": "refined-brake"
      },
      "source": [
        "## Modélisation avec kmeans KMeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "creative-affiliation",
      "metadata": {
        "id": "creative-affiliation",
        "outputId": "63a80024-e834-47e2-d8dc-d63d43094380"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'euclidean'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "\n",
        "\n",
        "kmeans = KMeans(k=3)\n",
        "kmeans.setSeed(10)\n",
        "kmeans.setFeaturesCol(\"selectedFeatures\")\n",
        "\n",
        "kmeans_model = kmeans.fit(data)\n",
        "kmeans_model.getDistanceMeasure()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gothic-energy",
      "metadata": {
        "id": "gothic-energy"
      },
      "outputs": [],
      "source": [
        "kmeans_predictions = kmeans_model.transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wired-remark",
      "metadata": {
        "id": "wired-remark",
        "outputId": "e0094858-09cf-4be1-86ca-ebf715e078d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|         0|\n",
            "|         0|\n",
            "|         0|\n",
            "|         2|\n",
            "|         2|\n",
            "+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "kmeans_predictions.select(\"prediction\").show(5, truncate=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "proprietary-devices",
      "metadata": {
        "id": "proprietary-devices",
        "outputId": "c4384df8-9975-4c67-ab3f-a6d0bb8990a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|         1|\n",
            "|         2|\n",
            "|         0|\n",
            "+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "kmeans_predictions.select(\"prediction\").distinct().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "durable-barrel",
      "metadata": {
        "id": "durable-barrel"
      },
      "outputs": [],
      "source": [
        "summary = kmeans_model.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "technological-stability",
      "metadata": {
        "id": "technological-stability",
        "outputId": "23272837-6dd8-4805-8ab5-db5f67df5395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- prediction: integer (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "summary.cluster.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "charitable-spain",
      "metadata": {
        "id": "charitable-spain"
      },
      "source": [
        "## Modélisation avec GaussianMixture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dimensional-wisdom",
      "metadata": {
        "id": "dimensional-wisdom"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.clustering import GaussianMixture\n",
        "\n",
        "gm = GaussianMixture(k=42, tol=0.01, seed=10, featuresCol=\"selectedFeatures\", maxIter=100)\n",
        "gm_model = gm.fit(data)\n",
        "\n",
        "gm_predictions = gm_model.transform(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "third-wonder",
      "metadata": {
        "id": "third-wonder"
      },
      "source": [
        "afficher les params du modèle en utilisant `explainParams()` functionalité:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "electric-chaos",
      "metadata": {
        "id": "electric-chaos",
        "outputId": "e733785c-a983-4b58-a31d-3faae787e580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\\n'\n",
            " 'featuresCol: features column name. (default: features, current: '\n",
            " 'selectedFeatures)\\n'\n",
            " 'k: Number of independent Gaussians in the mixture model. Must be > 1. '\n",
            " '(default: 2, current: 42)\\n'\n",
            " 'maxIter: max number of iterations (>= 0). (default: 100, current: 100)\\n'\n",
            " 'predictionCol: prediction column name. (default: prediction)\\n'\n",
            " 'probabilityCol: Column name for predicted class conditional probabilities. '\n",
            " 'Note: Not all models output well-calibrated probability estimates! These '\n",
            " 'probabilities should be treated as confidences, not precise probabilities. '\n",
            " '(default: probability)\\n'\n",
            " 'seed: random seed. (default: 259027761374774626, current: 10)\\n'\n",
            " 'tol: the convergence tolerance for iterative algorithms (>= 0). (default: '\n",
            " '0.01, current: 0.01)\\n'\n",
            " 'weightCol: weight column name. If this is not set or empty, we treat all '\n",
            " 'instance weights as 1.0. (undefined)')\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "params = gm_model.explainParams()\n",
        "pp.pprint(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handled-depth",
      "metadata": {
        "id": "handled-depth"
      },
      "source": [
        "# Création et ajustement du pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "blessed-blink",
      "metadata": {
        "id": "blessed-blink"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[hasher,selector, gm])\n",
        "# Fit the pipeline to training data.\n",
        "pipeline_model = pipeline.fit(co2_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adult-summit",
      "metadata": {
        "id": "adult-summit"
      },
      "outputs": [],
      "source": [
        "transformed_by_pipeline = pipeline_model.transform(co2_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "necessary-violation",
      "metadata": {
        "id": "necessary-violation",
        "outputId": "f24c14e7-568a-4e3c-c452-1de79726bb6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Make: string (nullable = true)\n",
            " |-- Model: string (nullable = true)\n",
            " |-- Vehicle Class: string (nullable = true)\n",
            " |-- Cylinders: double (nullable = false)\n",
            " |-- Transmission: string (nullable = true)\n",
            " |-- Fuel Type: string (nullable = true)\n",
            " |-- Fuel Consumption City (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Hwy (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (L/100 km): double (nullable = false)\n",
            " |-- Fuel Consumption Comb (mpg): double (nullable = false)\n",
            " |-- CO2: double (nullable = false)\n",
            " |-- hashed_features: vector (nullable = true)\n",
            " |-- selectedFeatures: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: integer (nullable = false)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transformed_by_pipeline.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "collect-serum",
      "metadata": {
        "id": "collect-serum"
      },
      "source": [
        "## Evaluation des modèles de clustring\n",
        "\n",
        "Ce code utilise la classe ClusteringEvaluator de PySpark pour évaluer les performances des modèles de clustering générés par les algorithmes KMeans (kmeans) et GaussianMixture (GM).\n",
        "\n",
        "- Tout d'abord, un objet evaluator est créé en spécifiant la colonne des caractéristiques sélectionnées (selectedFeatures) comme entrée.\n",
        "- Ensuite, la colonne de prédiction (prediction) est définie à l'aide de la méthode setPredictionCol.\n",
        "- Les performances des modèles sont ensuite évaluées à l'aide de la méthode evaluate de l'évaluateur sur les prédictions générées par les modèles KMeans (kmeans_predictions) et - GaussianMixture (gm_predictions) respectivement, en utilisant la distance euclidienne.\n",
        "- Cela permet de quantifier la qualité des clusters générés par les deux modèles en utilisant une métrique spécifique fournie par la classe ClusteringEvaluator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "european-grant",
      "metadata": {
        "id": "european-grant",
        "outputId": "16c2bc21-d9b5-4588-be24-ff6486e361a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kmeans: 0.6791002214675337\n",
            "GM: -0.1517797715036008\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "evaluator = ClusteringEvaluator(featuresCol='selectedFeatures')\n",
        "evaluator.setPredictionCol(\"prediction\")\n",
        "\n",
        "#evaluate with eucliden distance\n",
        "print(\"kmeans: \"+str(evaluator.evaluate(kmeans_predictions)))\n",
        "print(\"GM: \"+ str(evaluator.evaluate(gm_predictions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "expressed-exposure",
      "metadata": {
        "id": "expressed-exposure",
        "outputId": "73753a11-307c-4795-da85-7e31c01b3fbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluator.isLargerBetter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "silver-instrument",
      "metadata": {
        "id": "silver-instrument",
        "outputId": "24cd1529-0d8a-4048-b5b7-5bd33d69a82e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "kmeans: -0.07958234502129219\n",
            "GM: -0.19012403274289733\n"
          ]
        }
      ],
      "source": [
        "evaluator.setDistanceMeasure(\"cosine\")\n",
        "print(\"kmeans: \"+str(evaluator.evaluate(kmeans_predictions)))\n",
        "print(\"GM: \"+ str(evaluator.evaluate(gm_predictions)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "novel-brother",
      "metadata": {
        "id": "novel-brother",
        "outputId": "0cb46dbe-ea75-49ae-e365-3db9e562db9a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluator.isLargerBetter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mysterious-press",
      "metadata": {
        "id": "mysterious-press",
        "outputId": "ade98aaa-697b-4c7f-f43a-4c5cf3efce42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"distanceMeasure: The distance measure. Supported options: 'squaredEuclidean' and 'cosine'. (default: squaredEuclidean, current: cosine)\\nfeaturesCol: features column name. (default: features, current: selectedFeatures)\\nmetricName: metric name in evaluation (silhouette) (default: silhouette)\\npredictionCol: prediction column name. (default: prediction, current: prediction)\\nweightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\""
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluator.explainParams()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "round-saudi",
      "metadata": {
        "id": "round-saudi"
      },
      "source": [
        "#### Étant donné que la sortie de l'évaluateur pour isLargerBetter était vraie, nous pouvons définir que l'algorithme KMeans a produit un meilleur modèle que GM.\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "possible-genome",
      "metadata": {
        "id": "possible-genome"
      },
      "source": [
        "# Experimentation des Hyperparameters et du Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "documented-stranger",
      "metadata": {
        "id": "documented-stranger",
        "outputId": "3617fa2a-13a3-432b-8800-97aa3afc2607"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
        "\n",
        "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]).build()\n",
        "\n",
        "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
        "                           collectSubModels=True, parallelism=1, seed=42)\n",
        "tvs_model = tvs.fit(data)\n",
        "tvs_model.getTrainRatio()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skilled-opposition",
      "metadata": {
        "id": "skilled-opposition",
        "outputId": "9a052d20-326a-4c0b-c378-43e2911437a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.06270405194965402, -0.06402059325959049, -0.06402059325959049]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tvs_model.validationMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interesting-telescope",
      "metadata": {
        "id": "interesting-telescope"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
        "\n",
        "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
        "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']).build()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transsexual-georgia",
      "metadata": {
        "id": "transsexual-georgia",
        "outputId": "3c6f2c5c-2159-4718-9015-b2560d5e21ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.06270405194965402, -0.06402059325959049, -0.06402059325959049]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tvs_model.validationMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tested-sleeping",
      "metadata": {
        "id": "tested-sleeping",
        "outputId": "b2172aed-386a-44d5-8aac-fd7b83707979"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.06292946960479909,\n",
              " -0.06292946960479909,\n",
              " 0.5520132682136769,\n",
              " 0.5520132682136769,\n",
              " -0.06292946960479909,\n",
              " -0.06292946960479909,\n",
              " 0.5520132682136769,\n",
              " 0.5520132682136769,\n",
              " -0.06292946960479909,\n",
              " -0.06292946960479909,\n",
              " 0.5520132682136769,\n",
              " 0.5520132682136769]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
        "\n",
        "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
        "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']) \\\n",
        "        .addGrid(evaluator.distanceMeasure, ['euclidean','cosine']).build()\n",
        "\n",
        "\n",
        "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
        "                           collectSubModels=True, parallelism=1, seed=42, trainRatio=0.8)\n",
        "tvs_model = tvs.fit(data)\n",
        "tvs_model.validationMetrics\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sealed-fisher",
      "metadata": {
        "id": "sealed-fisher"
      },
      "source": [
        "## Ajout d'un evaluateur au grid params:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "individual-government",
      "metadata": {
        "id": "individual-government",
        "outputId": "06047f27-d666-4aa4-fa15-0341d135846d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.06292946960479909,\n",
              " -0.06292946960479909,\n",
              " 0.5520132682136769,\n",
              " 0.5520132682136769,\n",
              " -0.06292946960479909,\n",
              " -0.06292946960479909,\n",
              " 0.5520132682136769,\n",
              " 0.5520132682136769,\n",
              " -0.06292946960479909,\n",
              " -0.06292946960479909,\n",
              " 0.5520132682136769,\n",
              " 0.5520132682136769]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.tuning import TrainValidationSplit , ParamGridBuilder\n",
        "\n",
        "\n",
        "grid = ParamGridBuilder().addGrid(kmeans.maxIter, [20,50,100]) \\\n",
        "        .addGrid(kmeans.distanceMeasure, ['euclidean','cosine']) \\\n",
        "        .addGrid(evaluator.distanceMeasure, ['euclidean','cosine'])\\\n",
        "        .baseOn({kmeans.featuresCol: 'selectedFeatures'}) \\\n",
        "        .build()\n",
        "\n",
        "tvs = TrainValidationSplit(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
        "                           collectSubModels=True, parallelism=1, seed=42, trainRatio=0.8)\n",
        "tvs_model = tvs.fit(data)\n",
        "tvs_model.validationMetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "swedish-annex",
      "metadata": {
        "id": "swedish-annex",
        "outputId": "54b668e9-f101-4ac7-b717-1e8524569d0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              " KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tvs_model.subModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "amended-personality",
      "metadata": {
        "id": "amended-personality"
      },
      "outputs": [],
      "source": [
        "arr_models = tvs_model.subModels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "incorrect-harris",
      "metadata": {
        "id": "incorrect-harris"
      },
      "source": [
        "# Split Les modèles"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e64dac5f",
      "metadata": {
        "id": "e64dac5f"
      },
      "source": [
        "Dans cette partie du code, une technique cruciale appelée validation croisée est mise en œuvre pour optimiser les paramètres du modèle. La validation croisée, réalisée ici à l'aide de la classe CrossValidator de PySpark, divise les données en plusieurs sous-ensembles et effectue plusieurs entraînements et évaluations du modèle sur différentes combinaisons de ces sous-ensembles. Cela permet d'estimer de manière fiable les performances du modèle et d'ajuster les hyperparamètres pour obtenir les meilleurs résultats possibles. En spécifiant le modèle (kmeans), les paramètres à tester (grid), et l'évaluateur (evaluator), ainsi que d'autres paramètres tels que le nombre de plis (numFolds), la validation croisée permet de comparer objectivement les performances du modèle avec différentes configurations. Enfin, en accédant aux sous-modèles (subModels), nous pouvons examiner les modèles spécifiques générés lors de chaque itération de la validation croisée, ce qui peut fournir des informations précieuses sur la manière dont le modèle fonctionne avec différentes combinaisons de paramètres."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "worthy-arrest",
      "metadata": {
        "id": "worthy-arrest",
        "outputId": "363c8d34-8367-4852-f7f6-b5324aab8d38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50],\n",
              " [KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50],\n",
              " [KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=euclidean, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50,\n",
              "  KMeansModel: uid=KMeans_792430fa1bb8, k=3, distanceMeasure=cosine, numFeatures=50]]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel\n",
        "\n",
        "\n",
        "cv = CrossValidator(estimator=kmeans, estimatorParamMaps=grid, evaluator=evaluator,\n",
        "                           collectSubModels=True,  parallelism=2, numFolds=3)\n",
        "\n",
        "cv_model = cv.fit(data)\n",
        "cv_model.subModels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "defensive-cardiff",
      "metadata": {
        "id": "defensive-cardiff",
        "outputId": "78eea283-f4fb-4bae-923f-c7f476778b95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cv_model.subModels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "novel-relay",
      "metadata": {
        "id": "novel-relay",
        "outputId": "2acdbd11-e126-473b-a8a4-9529322b6733"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(cv_model.subModels[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aboriginal-scale",
      "metadata": {
        "id": "aboriginal-scale",
        "outputId": "becb406f-686f-45b7-8bc3-a000dc680a8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.08053007809073798,\n",
              " -0.08053007809073798,\n",
              " 0.5989818334335287,\n",
              " 0.5989818334335287,\n",
              " -0.07970600680061901,\n",
              " -0.07970600680061901,\n",
              " 0.5989818334335287,\n",
              " 0.5989818334335287,\n",
              " -0.07970600680061901,\n",
              " -0.07970600680061901,\n",
              " 0.5989818334335287,\n",
              " 0.5989818334335287]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv_model.avgMetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ab28255",
      "metadata": {
        "id": "8ab28255"
      },
      "source": [
        "# ***Conclusion***\n",
        "\n",
        "Ce projet de clustering des émissions de CO2 des véhicules au Canada a permis de démontrer l'efficacité des techniques de machine learning pour segmenter les données en groupes significatifs. En utilisant Apache Spark, nous avons pu traiter et analyser de grandes quantités de données de manière efficace, ce qui est essentiel pour des applications à grande échelle. Les résultats obtenus avec les algorithmes de clustering tels que KMeans et GaussianMixture, ainsi que l'évaluation de ces modèles, montrent des perspectives prometteuses pour l'identification des caractéristiques influençant les émissions de CO2. En conclusion, ce projet illustre comment l'application des technologies de big data et de machine learning peut contribuer à des analyses environnementales approfondies et à la prise de décisions éclairées pour la réduction des émissions de CO2."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8292ff61"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}